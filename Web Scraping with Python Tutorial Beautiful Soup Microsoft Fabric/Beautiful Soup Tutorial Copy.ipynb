{"cells":[{"cell_type":"markdown","id":"6119572d-a8eb-4374-a561-2d7469503e7d","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["# Tutorial from: Web Scraping in Python with Beautiful Soup and Requests\n","# by Jan Kirenz\n","# https://www.kirenz.com/post/2022-05-02-web-scraping-in-python-with-beautiful-soup-requests-and-pandas/"]},{"cell_type":"markdown","id":"ab04b234-fdf0-4bab-98ea-d023fb0403c2","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["## Call our Packages pandas, requests, and BeautifulSoup.  Load up our test url and get the results."]},{"cell_type":"code","execution_count":null,"id":"bdd810ce-b7ae-4d78-8b30-9efceb38389c","metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","import requests\n","from bs4 import BeautifulSoup\n","\n","url = 'http://quotes.toscrape.com/'\n","\n","html = requests.get(url)\n","\n","html"]},{"cell_type":"markdown","id":"7791ae81-57b0-4eee-ad52-de4aa9f7194a","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["## How do we read the information we've scrapped?"]},{"cell_type":"code","execution_count":null,"id":"c3597511-8bbb-4bd9-9736-ff0bb69a3a03","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["soup = BeautifulSoup(html.text, 'html.parser')\n","print(soup.prettify())"]},{"cell_type":"markdown","id":"7f91971b-1e6d-4dbf-a5a7-2e815fdec703","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### The title of the page may have data that we want to store.  How do we get this? "]},{"cell_type":"code","execution_count":null,"id":"d4ce4798-8e4a-4a6d-b7d2-e5a6b4c2e050","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["soup.title"]},{"cell_type":"code","execution_count":null,"id":"9b54de5e-45ba-4d60-a154-d3610284f0ba","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["soup.title.name"]},{"cell_type":"code","execution_count":null,"id":"732b9fba-e703-43a9-80dc-265ae271e8c7","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["soup.title.string"]},{"cell_type":"markdown","id":"9c6b4d10-b2ab-43dc-bc87-6851e03cedd0","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### We can also get the first link on the page by using the .a attribute"]},{"cell_type":"code","execution_count":null,"id":"9bf3ff6e-b728-4020-a7b4-acc161e06060","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["soup.a"]},{"cell_type":"markdown","id":"2fecd4b0-ed5c-4775-a6a3-bc9cb7c45e21","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Now try the first text element in the code"]},{"cell_type":"code","execution_count":null,"id":"ec7e7f5d-28e5-4c7f-881a-56b4bddd8830","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["soup.span.text"]},{"cell_type":"markdown","id":"89e73fc4-bbad-496d-8ae1-c969a91dede6","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### The quotes appear to be divided by div tags titled by class type 'quote'"]},{"cell_type":"code","execution_count":null,"id":"e6c56f99-aeea-42cd-a303-dd1f02bce0c0","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["quotes = soup.find_all('div', {'class': 'quote'})\n","\n","quotes"]},{"cell_type":"markdown","id":"792df30c-4255-470f-8e8b-762ae0061b7f","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Let's make the retrieval more legible "]},{"cell_type":"code","execution_count":null,"id":"aee5c29d-4e4d-417c-98b0-404d94f73b41","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["quotes = soup.find_all('div', {'class': 'quote'})\n","\n","for i in quotes:\n","    print((i.find('span', {'class':'text'})).text)"]},{"cell_type":"markdown","id":"60cb4591-e531-4451-acab-5ddfb868c931","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Let's look for the authors"]},{"cell_type":"code","execution_count":null,"id":"8fa5c532-6015-4404-9602-ba6e0da76070","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["for i in soup.findAll(\"div\",{\"class\": \"quote\"}):\n","    print((i.find(\"small\", {\"class\": \"author\"})).text)"]},{"cell_type":"markdown","id":"ed1dca57-8588-4b60-8633-150bcabd8d8b","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Now the additional meta data on the page"]},{"cell_type":"code","execution_count":null,"id":"2580d5f0-3cd2-4f90-90cb-beb5a9cec583","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["for i in soup.findAll(\"div\",{\"class\": \"tags\"}):\n","    print((i.find(\"meta\"))['content'])"]},{"cell_type":"markdown","id":"2c5cbac2-aa8f-4f24-ba1e-53a4289293c7","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### All of this is great but how do we put this in a table?"]},{"cell_type":"code","execution_count":null,"id":"ba9f3dfe-2a62-4f08-bda5-e419203f9a39","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# store root url without page number\n","root = 'http://quotes.toscrape.com/page/'\n","\n","# create empty arrays\n","quotes = []\n","authors = []\n","tags = []\n","\n","# loop over page 1 to 10\n","for pages in range(1,10): \n","        \n","        html = requests.get(root + str(pages))\n","        \n","        soup = BeautifulSoup(html.text)    \n","\n","        for i in soup.findAll(\"div\",{\"class\":\"quote\"}):\n","                 quotes.append((i.find(\"span\",{\"class\":\"text\"})).text)  \n","   \n","        for j in soup.findAll(\"div\",{\"class\":\"quote\"}):\n","                 authors.append((j.find(\"small\",{\"class\":\"author\"})).text)    \n","        \n","        for k in soup.findAll(\"div\",{\"class\":\"tags\"}):\n","                 tags.append((k.find(\"meta\"))['content'])\n","\n","df = pd.DataFrame(\n","    {'Quotes':quotes,\n","     'Authors':authors,\n","     'Tags':tags\n","    })"]},{"cell_type":"markdown","id":"d7666939-5b2c-4611-8e69-98a750ff77ab","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Print our Dataframe"]},{"cell_type":"code","execution_count":null,"id":"81700da9-83d8-48f3-b65d-61c5728d0628","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"id":"bf620c7f-f050-49e5-a737-a11b4c279e98","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["AuthorQuotes = spark.createDataFrame(df)"]},{"cell_type":"code","execution_count":null,"id":"bbe27a98-fb4e-4acf-a950-b652e1e582f1","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["AuthorQuotes.write.format(\"Delta\").save(\"Tables/AuthorQuotes\")"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"","default_lakehouse_name":"baseball_Lakehouse","default_lakehouse_workspace_id":""}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
